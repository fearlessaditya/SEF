{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d31a7bd5-01f9-41b3-a307-952dcc21f9d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n",
      "Device set to use mps:0\n",
      "Device set to use mps:0\n",
      "Some weights of T5ForSequenceClassification were not initialized from the model checkpoint at mrm8488/t5-base-finetuned-sarcasm-twitter and are newly initialized: ['classification_head.dense.bias', 'classification_head.dense.weight', 'classification_head.out_proj.bias', 'classification_head.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "import re\n",
    "import tkinter as tk\n",
    "from tkinter import messagebox\n",
    "from transformers import pipeline\n",
    "\n",
    "# -------------------------\n",
    "# Config / thresholds\n",
    "# -------------------------\n",
    "TOX_THRESHOLD = 0.35         # direct toxicity threshold (tune)\n",
    "NEG_SENT_THRESH = 0.60       # negative sentiment threshold\n",
    "SARCASM_THRESH = 0.60        # sarcasm confidence threshold\n",
    "THREAT_REGEX = re.compile(r\"\\b(i\\s+will|i'll|i am going to|im gonna|i'm going to)\\b.*\\b(kill|hurt|destroy|shoot|stab|die|beat)\\b\", re.I)\n",
    "\n",
    "# -------------------------\n",
    "# Whitelist & special cases\n",
    "# -------------------------\n",
    "WHITELIST = {\n",
    "    \"allah u akbar\",\n",
    "    \"allahu akbar\",\n",
    "    \"om namah shivay\",\n",
    "    \"hallelujah\",\n",
    "    # extend with common benign phrases you want to never flag\n",
    "}\n",
    "\n",
    "# Phrases we know are coded slurs or special toxic lexicalizations (domain specific)\n",
    "SPECIAL_CASES = {\n",
    "    \"ola u uber\": [\"coded_religious_slur\"],\n",
    "    # add other exact normalized mappings as you discover them\n",
    "}\n",
    "\n",
    "# Polite phrases that often get mis-detected as sarcastic — suppress sarcasm tagging if exact match (or substring)\n",
    "POLITE_PHRASES = [\n",
    "    \"have a nice day\",\n",
    "    \"have a good day\",\n",
    "    \"nice meeting you\",\n",
    "    \"good luck\",\n",
    "    \"thank you\",\n",
    "    \"thanks\",\n",
    "    \"have a great day\",\n",
    "    \"take care\",\n",
    "]\n",
    "\n",
    "# -------------------------\n",
    "# Load models\n",
    "# -------------------------\n",
    "# Note: these model loads can be slow on first run.\n",
    "toxicity_model = pipeline(\"text-classification\", model=\"unitary/toxic-bert\", top_k=None)\n",
    "emotion_model  = pipeline(\"text-classification\", model=\"bhadresh-savani/distilbert-base-uncased-emotion\", top_k=None)\n",
    "sentiment_model= pipeline(\"sentiment-analysis\", model=\"distilbert/distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "# Sarcasm T5 model requires extra deps; if you had issues before you may switch to a different sarcasm model.\n",
    "sarcasm_model  = pipeline(\"text-classification\", model=\"mrm8488/t5-base-finetuned-sarcasm-twitter\")\n",
    "\n",
    "# -------------------------\n",
    "# Helper: normalize\n",
    "# -------------------------\n",
    "def normalize_text(s: str) -> str:\n",
    "    return re.sub(r'\\s+', ' ', s.strip().lower())\n",
    "\n",
    "# -------------------------\n",
    "# Main analyze function\n",
    "# -------------------------\n",
    "def analyze_text(message,\n",
    "                 tox_threshold=TOX_THRESHOLD,\n",
    "                 neg_sent_thresh=NEG_SENT_THRESH,\n",
    "                 sarcasm_thresh=SARCASM_THRESH):\n",
    "    norm = normalize_text(message)\n",
    "\n",
    "    # 0) Whitelist / exact safe phrase early exit\n",
    "    if norm in WHITELIST:\n",
    "        return {\n",
    "            \"input\": message,\n",
    "            \"toxic_tags\": [],\n",
    "            \"emotion\": (\"neutral\", 1.0),\n",
    "            \"sentiment\": {\"label\": \"NEUTRAL\", \"score\": 1.0},\n",
    "            \"raw_toxicity\": {},\n",
    "            \"sarcasm\": (\"LABEL_0\", 0.0),\n",
    "            \"special_flags\": [],\n",
    "            \"notes\": [\"whitelisted exact phrase\"]\n",
    "        }\n",
    "\n",
    "    notes = []\n",
    "    special_flags = SPECIAL_CASES.get(norm, [])\n",
    "\n",
    "    # 1) Toxicity model (multi-label)\n",
    "    tox_preds = toxicity_model(message)[0]  # list of dicts\n",
    "    raw_tox = {p['label']: p['score'] for p in tox_preds}\n",
    "    direct_toxic = [lbl for lbl, s in raw_tox.items() if s > tox_threshold]\n",
    "\n",
    "    # 1.1 Threat regex (explicit threat detection)\n",
    "    threat_found = False\n",
    "    if THREAT_REGEX.search(message):\n",
    "        if \"threat\" not in direct_toxic:\n",
    "            direct_toxic.append(\"threat\")\n",
    "        threat_found = True\n",
    "        notes.append(\"threat_regex_matched\")\n",
    "\n",
    "    # 1.2 If special_cases matched, append those flags (these are domain-specific)\n",
    "    if special_flags:\n",
    "        direct_toxic.extend(special_flags)\n",
    "        notes.append(\"matched_special_case\")\n",
    "\n",
    "    # 2) Sentiment\n",
    "    sent = sentiment_model(message)[0]  # {'label': 'POSITIVE'/'NEGATIVE', 'score':...}\n",
    "\n",
    "    # 3) Emotion (handle nested output)\n",
    "    emo_raw = emotion_model(message)\n",
    "    if isinstance(emo_raw[0], list):\n",
    "        emo_raw = emo_raw[0]\n",
    "    emotion_label = emo_raw[0]['label']\n",
    "    emotion_score = emo_raw[0]['score']\n",
    "\n",
    "    # 3.5 Polite-phrase suppression: if message contains a polite phrase substring, suppress sarcasm tagging\n",
    "    polite_hit = any(phrase in norm for phrase in POLITE_PHRASES)\n",
    "    if polite_hit:\n",
    "        notes.append(\"polite_phrase_suppressed_sarcasm\")\n",
    "\n",
    "    # 4) Sarcasm model\n",
    "    sarc_raw = sarcasm_model(message)[0]  # {'label': 'LABEL_0'/'LABEL_1', 'score':...}\n",
    "    sarc_label = sarc_raw.get('label', 'LABEL_0')\n",
    "    sarc_score = float(sarc_raw.get('score', 0.0))\n",
    "    is_sarcastic = (sarc_label == \"LABEL_1\" and sarc_score >= sarcasm_thresh)\n",
    "\n",
    "    # 5) Decide sarcasm-based tags (only if no direct toxicity and not a threat)\n",
    "    sarcastic_praise = False\n",
    "    sarcastic_insult = False\n",
    "    if not direct_toxic and not threat_found and is_sarcastic and not polite_hit:\n",
    "        # If sarcasm + positive sentiment + joyful emotion => sarcastic_praise (taunting praise)\n",
    "        if sent['label'] == \"POSITIVE\" and emotion_label in (\"joy\", \"surprise\"):\n",
    "            sarcastic_praise = True\n",
    "            notes.append(\"sarcastic_praise_detected\")\n",
    "        # If sarcasm + negative sentiment or anger => sarcastic_insult\n",
    "        elif sent['label'] == \"NEGATIVE\" or emotion_label == \"anger\":\n",
    "            sarcastic_insult = True\n",
    "            notes.append(\"sarcastic_insult_detected\")\n",
    "        # Otherwise, if sentiment neutral but emotion angry -> insult\n",
    "        elif sent['label'] == \"NEUTRAL\" and emotion_label == \"anger\":\n",
    "            sarcastic_insult = True\n",
    "            notes.append(\"sarcastic_insult_from_anger\")\n",
    "\n",
    "    # 6) Negative sentiment catch-all (only if not direct toxic and not joyful)\n",
    "    negative_sentiment_flag = False\n",
    "    if not direct_toxic and not sarcastic_insult and not sarcastic_praise:\n",
    "        if sent['label'] == \"NEGATIVE\" and sent['score'] > neg_sent_thresh and emotion_label != \"joy\":\n",
    "            negative_sentiment_flag = True\n",
    "            notes.append(\"negative_sentiment_detected\")\n",
    "\n",
    "    # 7) Combine final tags\n",
    "    toxic_tags = list(dict.fromkeys(direct_toxic))  # deduplicate preserve order\n",
    "    if sarcastic_praise:\n",
    "        toxic_tags.append(\"sarcastic_praise\")\n",
    "    if sarcastic_insult:\n",
    "        toxic_tags.append(\"sarcastic_insult\")\n",
    "    if negative_sentiment_flag:\n",
    "        toxic_tags.append(\"negative_sentiment\")\n",
    "\n",
    "    # 8) Build result\n",
    "    result = {\n",
    "        \"input\": message,\n",
    "        \"toxic_tags\": toxic_tags,\n",
    "        \"emotion\": (emotion_label, emotion_score),\n",
    "        \"sentiment\": sent,\n",
    "        \"raw_toxicity\": raw_tox,\n",
    "        \"sarcasm\": (sarc_label, sarc_score),\n",
    "        \"special_flags\": special_flags,\n",
    "        \"notes\": notes\n",
    "    }\n",
    "    return result\n",
    "\n",
    "# -------------------------\n",
    "# GUI\n",
    "# -------------------------\n",
    "def run_gui():\n",
    "    root = tk.Tk()\n",
    "    root.title(\"Enhanced Cyberbullying Detector — v2\")\n",
    "    root.geometry(\"680x640\")\n",
    "    root.resizable(False, False)\n",
    "\n",
    "    frame_top = tk.Frame(root)\n",
    "    frame_top.pack(pady=8)\n",
    "\n",
    "    tk.Label(frame_top, text=\"Enter Message:\", font=(\"Arial\", 12)).grid(row=0, column=0, sticky=\"w\")\n",
    "    text_entry = tk.Text(frame_top, height=4, width=80, font=(\"Arial\", 11))\n",
    "    text_entry.grid(row=1, column=0, columnspan=4, padx=8, pady=6)\n",
    "\n",
    "    # Buttons row\n",
    "    def clear_input():\n",
    "        text_entry.delete(\"1.0\", \"end\")\n",
    "        result_text.configure(state=\"normal\")\n",
    "        result_text.delete(\"1.0\", \"end\")\n",
    "        result_text.configure(state=\"disabled\")\n",
    "\n",
    "    clear_btn = tk.Button(frame_top, text=\"Clear\", command=clear_input)\n",
    "    clear_btn.grid(row=2, column=0, sticky=\"w\", padx=(8,4), pady=6)\n",
    "\n",
    "    auto_copy_var = tk.BooleanVar(value=False)\n",
    "    auto_copy_chk = tk.Checkbutton(frame_top, text=\"Auto-copy results\", variable=auto_copy_var)\n",
    "    auto_copy_chk.grid(row=2, column=1, sticky=\"w\", padx=4)\n",
    "\n",
    "    copy_btn = tk.Button(frame_top, text=\"Copy to Clipboard\", command=lambda: copy_to_clipboard(root, result_text))\n",
    "    copy_btn.grid(row=2, column=2, sticky=\"w\", padx=4)\n",
    "\n",
    "    # Result display (selectable text)\n",
    "    tk.Label(root, text=\"Analysis Result:\", font=(\"Arial\", 12)).pack(pady=(10,0))\n",
    "    result_text = tk.Text(root, height=24, width=82, font=(\"Courier\", 10), wrap=\"word\")\n",
    "    result_text.pack(padx=10, pady=6)\n",
    "    result_text.configure(state=\"disabled\")  # read-only until we write\n",
    "\n",
    "    # helper\n",
    "    def copy_to_clipboard(root_win, text_widget):\n",
    "        content = text_widget.get(\"1.0\", \"end-1c\")\n",
    "        if content.strip():\n",
    "            root_win.clipboard_clear()\n",
    "            root_win.clipboard_append(content)\n",
    "            messagebox.showinfo(\"Copied\", \"Results copied to clipboard.\")\n",
    "        else:\n",
    "            messagebox.showinfo(\"Nothing\", \"No results to copy.\")\n",
    "\n",
    "    # Analyze action\n",
    "    def on_analyze():\n",
    "        msg = text_entry.get(\"1.0\", \"end\").strip()\n",
    "        if not msg:\n",
    "            messagebox.showwarning(\"Input Required\", \"Please enter a message.\")\n",
    "            return\n",
    "\n",
    "        # run analysis\n",
    "        try:\n",
    "            res = analyze_text(msg)\n",
    "        except Exception as e:\n",
    "            messagebox.showerror(\"Analysis error\", str(e))\n",
    "            return\n",
    "\n",
    "        # Format output text\n",
    "        out_lines = []\n",
    "        out_lines.append(\"Input:\")\n",
    "        out_lines.append(res[\"input\"])\n",
    "        out_lines.append(\"\")\n",
    "        out_lines.append(\"Toxic tags: \" + (\", \".join(res[\"toxic_tags\"]) or \"None\"))\n",
    "        emo, emo_score = res[\"emotion\"]\n",
    "        out_lines.append(f\"Emotion: {emo} ({emo_score:.2f})\")\n",
    "        sent = res[\"sentiment\"]\n",
    "        out_lines.append(f\"Sentiment: {sent['label']} ({sent['score']:.2f})\")\n",
    "        sarc_label, sarc_score = res[\"sarcasm\"]\n",
    "        out_lines.append(f\"Sarcasm: {sarc_label} (p={sarc_score:.2f})\")\n",
    "        if res[\"special_flags\"]:\n",
    "            out_lines.append(\"Special flags: \" + \", \".join(res[\"special_flags\"]))\n",
    "        if res[\"notes\"]:\n",
    "            out_lines.append(\"Notes: \" + \"; \".join(res[\"notes\"]))\n",
    "        out_lines.append(\"\")\n",
    "        out_lines.append(\"Raw toxicity scores:\")\n",
    "        if res[\"raw_toxicity\"]:\n",
    "            out_lines.extend(f\"{k}: {v:.2f}\" for k, v in res[\"raw_toxicity\"].items())\n",
    "        else:\n",
    "            out_lines.append(\"(none)\")\n",
    "\n",
    "        out_text = \"\\n\".join(out_lines)\n",
    "\n",
    "        # show in result box\n",
    "        result_text.configure(state=\"normal\")\n",
    "        result_text.delete(\"1.0\", \"end\")\n",
    "        result_text.insert(\"1.0\", out_text)\n",
    "        result_text.configure(state=\"disabled\")\n",
    "\n",
    "        # auto-copy if requested\n",
    "        if auto_copy_var.get():\n",
    "            copy_to_clipboard(root, result_text)\n",
    "\n",
    "    analyze_btn = tk.Button(root, text=\"Analyze\", font=(\"Arial\", 12), command=on_analyze)\n",
    "    analyze_btn.pack(pady=(6,12))\n",
    "\n",
    "    root.mainloop()\n",
    "\n",
    "# run it\n",
    "run_gui()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078ba487-4ca2-40c0-b313-2375493048d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (chat-moderation-env)",
   "language": "python",
   "name": "chat-moderation-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
